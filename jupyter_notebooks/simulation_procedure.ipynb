{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jn_setup\n",
    "import os, pandas as pd, numpy as np, pickle\n",
    "import pytest_shutil, shutil, regex as re, dask, uuid\n",
    "from pyswmm import Simulation\n",
    "import swmmtoolbox.swmmtoolbox as swmmtoolbox\n",
    "import time\n",
    "from pyswmm.lib import DLL_SELECTION\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up start up vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set mode: 'test' or 'run'\n",
    "Test mode is designed to test code quickly by using a small sample of the data instead of the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate \n",
    "mode = 'debug'\n",
    "# mode = 'test'\n",
    "# mode = 'run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To activate debug mode, run 'inp_path = set_inp_path('debug')'.\n",
      "To activate test mode, run 'inp_path = set_inp_path('test')'.\n",
      "To activate run mode, run 'inp_path = set_inp_path('run')'.\n"
     ]
    }
   ],
   "source": [
    "from tools.paths import *\n",
    "from tools.functions import *\n",
    "\n",
    "# this is the path to the default dynamic link library used for running SWMM\n",
    "# used by 04\n",
    "dll_path = DLL_SELECTION()\n",
    "dll_bn = os.path.basename(dll_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 7 outfall names\n",
    "# used by 05+ \n",
    "if mode == \"debug\":\n",
    "    outfalls = ['outfall_31_28']\n",
    "else:\n",
    "    outfalls = ['outfall_31_26', 'outfall_31_28', 'outfall_31_29', 'outfall_31_35',\n",
    "                'outfall_31_36', 'outfall_31_38', 'outfall_31_42']\n",
    "\n",
    "# sub_list_area has the areas of each subcatchment in order\n",
    "# used by 05\n",
    "with open(os.path.join(master_path,'sub_list_area.txt'),'r') as read_file:\n",
    "    sub_list_area = eval(read_file.read())\n",
    "\n",
    "# sub_ids is the dictionary detailing which subcatchments make up which outfalls\n",
    "# used by 05\n",
    "with open(os.path.join(master_path,'outfall_partition.txt'),'r') as read_file:\n",
    "    sub_ids = eval(read_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jstelman\\Git\\stelman_urban_pesticides\\master_debug\\NPlesantCreek.inp\n"
     ]
    }
   ],
   "source": [
    "# activate test mode\n",
    "inp_path = set_inp_path(mode)\n",
    "print(inp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for debug mode\n",
    "# from pyDOE2 import lhs\n",
    "# from scipy.stats import uniform\n",
    "# swmm_ranges = pd.read_csv(os.path.join(master_path, \"lhs_param_ranges.csv\"), index_col=0,\n",
    "#                            usecols = [\"Parameter\",\"Min\", \"Range\"])\n",
    "# vvwm_ranges = pd.read_csv(os.path.join(master_path, \"lhs_param_ranges_vvwm.csv\"), index_col=0,\n",
    "#                            usecols = [\"Parameter\",\"Min\", \"Range\"])\n",
    "# param_ranges = pd.concat([swmm_ranges, vvwm_ranges], axis = 0)\n",
    "# del swmm_ranges, vvwm_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up input variables and run id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nMAKE SURE TO SWITCH WP AND FC IN THE FILE! THEY ARE BACKWARDS AND IT'S ANNOYING\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "MAKE SURE TO SWITCH WP AND FC IN THE FILE! THEY ARE BACKWARDS AND IT'S ANNOYING\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Observed Data\n",
    "obs_data = pd.read_csv(obs_path, usecols=[\"Sample_date\", \"Site_code\"],\n",
    "                       parse_dates=[\"Sample_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test parameter input\n",
    "if mode == \"debug\":\n",
    "    with open(os.path.join(main_path,'master_debug','debug_params.txt'),'r') as read_file:\n",
    "        params1 = eval(read_file.read())\n",
    "    # get them into the objects we need\n",
    "    swmm_keys = list(params1.keys())[:1]\n",
    "    vvwm_keys = list(params1.keys())[1:]\n",
    "    swmm_params = {key: params1[key] for key in swmm_keys}\n",
    "    vvwm_params = {key: params1[key] for key in vvwm_keys}\n",
    "    # lhs1 = lhs(n=36, samples=1)[0]\n",
    "    # for i in range(0,36):\n",
    "    #     lhs1[i] = param_ranges[\"Min\"][i] + (lhs1[i])*(param_ranges[\"Range\"][i])\n",
    "    # params1 = {}\n",
    "    # for key,value in list(zip(param_ranges.index, lhs1)):\n",
    "    #     params1[key] = value\n",
    "    # # now the arguments being passed in\n",
    "    # with open(os.path.join(main_path,'master_debug','debug_params.txt'),'r') as read_file:\n",
    "    #     params2 = eval(read_file.read())\n",
    "    # for key in list(params2.keys()):\n",
    "    #     params1[key] = params2[key]\n",
    "    # # error prevention\n",
    "    # if params1['MaxRate'] < params1['MinRate']:\n",
    "    #     params1['MaxRate'], params1['MinRate'] = params1['MinRate'], params1['MaxRate']\n",
    "    # if params1['FC'] < params1['WP']:\n",
    "    #     params1['FC'], params1['WP'] = params1['WP'], params1['FC']\n",
    "\n",
    "    # # get them into the objects we need\n",
    "    # swmm_keys = list(params1.keys())[:17]\n",
    "\n",
    "    # # wp and fc in this object should be switched. FOR NOW:\n",
    "    # swmm_keys = swmm_keys[:10] + ['WP', 'FC'] + swmm_keys[12:]\n",
    "\n",
    "    # vvwm_keys = list(params1.keys())[17:]\n",
    "    # swmm_params = {key: params1[key] for key in swmm_keys}\n",
    "    # vvwm_params = {key: params1[key] for key in vvwm_keys}\n",
    "    \n",
    "if mode == \"test\":\n",
    "    with open(os.path.join(main_path,'master_test','test_params.txt'),'r') as read_file:\n",
    "        params1 = eval(read_file.read())\n",
    "    \n",
    "    # error prevention\n",
    "    if params1['MaxRate'] < params1['MinRate']:\n",
    "        params1['MaxRate'], params1['MinRate'] = params1['MinRate'], params1['MaxRate']\n",
    "    if params1['FC'] < params1['WP']:\n",
    "        params1['FC'], params1['WP'] = params1['WP'], params1['FC']\n",
    "        \n",
    "    # get them into the objects we need\n",
    "    swmm_keys = list(params1.keys())[:17]\n",
    "\n",
    "    # wp and fc in this object should be switched. FOR NOW:\n",
    "    swmm_keys = swmm_keys[:10] + ['WP', 'FC'] + swmm_keys[12:]\n",
    "\n",
    "    vvwm_keys = list(params1.keys())[17:]\n",
    "    swmm_params = {key: params1[key] for key in swmm_keys}\n",
    "    vvwm_params = {key: params1[key] for key in vvwm_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spin up simulation id with this cool too for generating random ids\n",
    "# sid = Ite = i = rpt = uuid.uuid4().hex[0:8]\n",
    "sid = uuid.uuid4().hex[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: make simulation-specific SWMM items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMight want to not name this thing \"NPlesantCreek\" in all the folders. \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Might want to not name this thing \"NPlesantCreek\" in all the folders. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make paths to (soon-to-be) directory & files for this simulation using sid\n",
    "\n",
    "# directory\n",
    "sdir_path = os.path.join(temp_path, sid)\n",
    "# input file\n",
    "sinp_path = os.path.join(sdir_path, sid) + \".inp\"\n",
    "# output file\n",
    "sout_path = os.path.join(sdir_path, sid) + \".out\"\n",
    "# report file\n",
    "srpt_path = os.path.join(sdir_path, sid) + \".rpt\"\n",
    "# dynamic link library file\n",
    "## basename\n",
    "sdll_bn = dll_bn[:dll_bn.rindex(\".\")] + '-' + sid + dll_bn[dll_bn.rindex(\".\"):]\n",
    "## full path\n",
    "sdll_path = os.path.join(sdir_path, sdll_bn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder  83d2e5e9  created \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jstelman\\\\Git\\\\stelman_urban_pesticides\\\\temp\\\\83d2e5e9\\\\swmm5-x64-83d2e5e9.dll'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the directory\n",
    "if not os.path.exists(sdir_path):\n",
    "    os.mkdir(sdir_path)\n",
    "    print(\"Folder \", sid, \" created\", \"\\n\")\n",
    "else:\n",
    "    print(\"Folder \", sid, \"already exists\")\n",
    "\n",
    "# write input file\n",
    "with open(inp_path, \"r\") as read_file, open(sinp_path, \"w\") as write_file:\n",
    "    filelines = read_file.readlines()\n",
    "\n",
    "    # first we need to correct some absolute paths, because they are currently only set to work on the author's computer\n",
    "    filelines = replace_infile_abspaths(filelines = filelines)\n",
    "    \n",
    "    if mode == \"debug\":\n",
    "        filelines[172:(172 + 113)] = editted_lines(swmm_dict = swmm_params, Num = 113, row_0 = 172, parameter = \"NImperv\", Col = 1, flines = filelines)\n",
    "    \n",
    "    elif mode == \"test\":\n",
    "        # 113 = number of subcatchments\n",
    "        #for c, par in enumerate([\"NImperv\", \"NPerv\", \"SImperv\", \"SPerv\", \"PctZero\"]):\n",
    "        for c, par in enumerate(swmm_keys[0:5]):\n",
    "            filelines[172:(172 + 113)] = editted_lines(swmm_dict = swmm_params, Num = 113, row_0 = 172, parameter = par, Col = c+1, flines = filelines)\n",
    "        #for c, par in enumerate([\"MaxRate\", \"MinRate\", \"Decay\", \"DryTime\"]):\n",
    "        for c, par in enumerate(swmm_keys[5:9]):\n",
    "            filelines[289:(289 + 113)] = editted_lines(swmm_dict = swmm_params, Num = 113, row_0 = 289, parameter = par, Col = c+1, flines = filelines)\n",
    "\n",
    "        # 1 = number of aquifers\n",
    "        #for c, par in enumerate([\"Por\", \"WP\", \"FC\", \"Ksat\"]):\n",
    "        for c, par in enumerate(swmm_keys[9:13]):\n",
    "            filelines[406:(406 + 1)] = editted_lines(swmm_dict = swmm_params, Num = 1, row_0 = 406, parameter = par, Col = c+1, flines = filelines)\n",
    "\n",
    "        # 195 = number of conduits\n",
    "        # filelines[734:(734 + 195)] = editted_lines(swmm_dict = swmm_params, Num = 195, row_0 = 734, parameter = \"Rough\", Col = 4, flines = filelines)\n",
    "\n",
    "        # 1 = number of pollutants\n",
    "        filelines[1125:(1125 + 1)] = editted_lines(swmm_dict = swmm_params, Num = 1, row_0 = 1125, parameter = \"Kdecay\", Col = 5, flines = filelines)\n",
    "        filelines[1371:(1371 + 1)] = editted_lines(swmm_dict = swmm_params, Num = 1, row_0 = 1371, parameter = \"BCoeff2\", Col = 4, flines = filelines)\n",
    "        filelines[1377:(1377 + 1)] = editted_lines(swmm_dict = swmm_params, Num = 1, row_0 = 1377, parameter = \"WCoeff2\", Col = 4, flines = filelines)\n",
    "    \n",
    "    write_file.writelines(filelines)\n",
    "\n",
    "# copy a dll file into sdll_path\n",
    "shutil.copyfile(dll_path, sdll_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute simulation\n",
    "In test mode, should take about 2-3 minutes. \n",
    "In run mode, should take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logger\n",
    "loginfo, logerror = log_prefixer(\"04\")\n",
    "\n",
    "# delete pre-existing .out, if present, in order to run swmm agreeably\n",
    "if os.path.exists(sout_path):\n",
    "    loginfo(\"Deleting current copy of <\" + sout_path + \"> so new copy can be created.\")\n",
    "    #print(\"Deleting current copy of <NPlesantCreek.out> so new copy can be created.\")\n",
    "    os.remove(sout_path)\n",
    "\n",
    "# load the model {no interaction, write (binary) results to sout_path, use the specified dll}\n",
    "\n",
    "sim = Simulation(inputfile=sinp_path, reportfile=srpt_path, outputfile=sout_path, swmm_lib_path=sdll_path)\n",
    "# if no errors were thrown, we procede with the simulation\n",
    "# simulate the loaded model\n",
    "loginfo(\"Executing SWMM simmulation with no interaction. Input from <\" + sinp_path + \">. Will store output in <\" + sout_path + \">.\")\n",
    "with sim as s:\n",
    "    for step in s:\n",
    "        pass\n",
    "    \n",
    "# # error handling\n",
    "# try:\n",
    "#     # the error should happen at these two lines if ever\n",
    "#     if params1['MaxRate'] < params1['MinRate']:\n",
    "#         raise SWMMException(error_code = 200, error_message = \"MaxRate < MinRate\")\n",
    "#     if params1['FC'] < params1['WP']:\n",
    "#         raise SWMMException(error_code = 200, error_message = \"FC < WP\")\n",
    "#     # if the problem is somewhere else, this will trigger it\n",
    "#     sim = Simulation(inputfile=sinp_path, reportfile=srpt_path, outputfile=sout_path, swmm_lib_path=sdll_path)\n",
    "#     # if no errors were thrown, we procede with the simulation\n",
    "#     # simulate the loaded model\n",
    "#     loginfo(\"Executing SWMM simmulation with no interaction. Input from <\" + sinp_path + \">. Will store output in <\" + sout_path + \">.\")\n",
    "#     with sim as s:\n",
    "#         for step in s:\n",
    "#             pass\n",
    "\n",
    "# # stop here if you \n",
    "# except SWMMException as err:\n",
    "#     print(err)\n",
    "#     logerror(\"Error in  input from <\" + sinp_path + \">. \" + str(err))\n",
    "#     print(swmm_params)\n",
    "#     if mode == 'test':\n",
    "#         with open(os.path.join(main_path,'master_test','test_err_handling.pkl'),'rb') as read_pkl:\n",
    "#             output_dict = pickle.load(read_pkl)\n",
    "         \n",
    "#     elif mode == 'run':\n",
    "#         with open(os.path.join(master_path,'err_handling.pkl'),'rb') as read_pkl:\n",
    "#             output_dict = pickle.load(read_pkl)\n",
    "        \n",
    "#     print(\"STOP HERE! Result reached.\")\n",
    "#     print(\"output_dict = \")\n",
    "#     print(output_dict)\n",
    "#     # os.system(\"rm -r \" + sdir_path + \"/\")\n",
    "#     # return(output_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the info to a safe place and then delete the whole temp folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract swmm outputs with swmmtoolbox and delete expensive binary files\n",
    "lab1, lab2 = 'subcatchment,,Runoff_rate', 'subcatchment,,Bifenthrin'\n",
    "runf = swmmtoolbox.extract(sout_path, lab1)\n",
    "bif = swmmtoolbox.extract(sout_path, lab2)\n",
    "\n",
    "loginfo(\"Deleting <\" + sdir_path + \"> contents to free up memory.\")\n",
    "os.system(\"rm \" + sdir_path + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute daily averages\n",
    "runf = runf.resample('D').mean()\n",
    "bif = bif.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion for vvwm for runoff and bifenthrin\n",
    "runf = runf.mul(86400).mul(0.01).div(sub_list_area)\n",
    "bif = bif.mul(runf.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder  83d2e5e9 outfall_31_28  created \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for o in outfalls:\n",
    "    # set pathways\n",
    "    outfall_dir = os.path.join(sdir_path, o)\n",
    "    \n",
    "    # make the directory\n",
    "    if not os.path.exists(outfall_dir):\n",
    "        os.mkdir(outfall_dir)\n",
    "        print(\"Folder \", sid, o, \" created\", \"\\n\")\n",
    "    else:\n",
    "        print(\"Folder \", sid, o, \"already exists\")\n",
    "    \n",
    "    # create .zts file \n",
    "    # has 1 at each subcatchment of outfall[o], and 0 at the rest\n",
    "    weights = np.array([(1 if x in sub_ids[o] else 0) for x in range(113)])\n",
    "    # we want the daily totals the runoff and bifenthrin within each outfall\n",
    "    # use dot product and the weights vector to evaluate this on the df\n",
    "    runf_sum = runf @ weights\n",
    "    bif_sum = bif @ weights\n",
    "    \n",
    "    # we want to combine tables and add filler and date-part columns\n",
    "    vvwm_df = pd.DataFrame({\"year\": runf_sum.index.year,\n",
    "                        \"month\": runf_sum.index.month,\n",
    "                        \"day\": runf_sum.index.day,\n",
    "                        \"runf_sum\": runf_sum,\n",
    "                        \"B\": 0,\n",
    "                        \"bif_sum\": bif_sum,\n",
    "                        \"MEp\":0\n",
    "                       })\n",
    "    \n",
    "    # read out into comma-delimited .txt file\n",
    "    vvwm_df.to_csv(os.path.join(outfall_dir, \"output.zts\"), \n",
    "                   header=False, index=False, sep=',')\n",
    "\n",
    "    # for this to work, we need to write 3 blank lines to the beginning\n",
    "    # read in the file we just wrote\n",
    "    with open(os.path.join(outfall_dir, \"output.zts\"), \"r\") as read_file:\n",
    "        filelines = read_file.readlines()\n",
    "    # write this back into it with 3 lines added to the beginning\n",
    "    with open(os.path.join(outfall_dir, \"output.zts\"), \"w\") as write_file:\n",
    "        # write blanks to dummy file\n",
    "        write_file.write('\\n\\n\\n')\n",
    "        # read lines from original and append to dummy file\n",
    "        write_file.writelines(filelines) #JMS 10-21-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blank df to populate\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "for o in outfalls:\n",
    "    # set pathways\n",
    "    outfall_dir = os.path.join(sdir_path, o)\n",
    "    outfall_file = os.path.join(outfall_dir, \"vvwmTransfer.txt\")\n",
    "    \n",
    "    with open(vvwmTransfer_path,\"r\") as read_file:\n",
    "        filelines = read_file.readlines()\n",
    "    \n",
    "    if mode == \"debug\":\n",
    "        filelines[4] = str(vvwm_params[vvwm_keys[0]]) + \"\\n\"\n",
    "        \n",
    "    elif mode == \"test\":\n",
    "\n",
    "        # why is it 1:8 and not 0:8? Is it a typo?\n",
    "        for c, param in enumerate(list(vvwm_keys)[0:8]): # changed from 1:8 2/19/21\n",
    "            filelines[c+4] = str(vvwm_params[param]) + \"\\n\"\n",
    "\n",
    "        filelines[17] = str(vvwm_params[vvwm_keys[8]]) + \"\\n\"\n",
    "\n",
    "        for c, param in enumerate(list(vvwm_keys)[9:15]):\n",
    "            filelines[c+40] = str(vvwm_params[param]) + \"\\n\"\n",
    "\n",
    "        for c, param in enumerate(list(vvwm_keys)[15:19]):\n",
    "            filelines[c+47] = str(vvwm_params[param]) + \"\\n\"\n",
    "\n",
    "    # enter script 9\n",
    "    '''\n",
    "    Should I keep this parallel?\n",
    "    If not, I don't need 7 copies of the weather file\n",
    "    If I do keep it parallel, how much time does that even save?\n",
    "    '''\n",
    "\n",
    "    ''' Keeping it parallel:'''\n",
    "    # update pathways\n",
    "    filelines[0] = os.path.join(outfall_dir, \"output\") + '\\n'\n",
    "    filelines[29] = os.path.join(outfall_dir, \"vvwm_wet.dvf\") + '\\n'\n",
    "    filelines[68] = os.path.join(outfall_dir, \"output_NPlesant_Custom_parent_daily.csv\") + '\\n'\n",
    "    filelines[69] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg1_daily.csv\") + '\\n'\n",
    "    filelines[70] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg2_daily.csv\") + '\\n'\n",
    "    filelines[71] = os.path.join(outfall_dir, \"output_NPlesant_Custom_parent_analysis.txt\") + '\\n'\n",
    "    filelines[72] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg1_analysis.txt\") + '\\n'\n",
    "    filelines[73] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg2_analysis.txt\") + '\\n'\n",
    "    filelines[74] = os.path.join(outfall_dir, \"output_NPlesant_Custom_parent_deem.rdf\") + '\\n'\n",
    "    filelines[75] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg1_deem.rdf\") + '\\n'\n",
    "    filelines[76] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg2_deem.rdf\") + '\\n'\n",
    "    filelines[77] = os.path.join(outfall_dir, \"output_NPlesant_Custom_parent_calendex.rdf\") + '\\n'\n",
    "    filelines[78] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg1_calendex.rdf\") + '\\n'\n",
    "    filelines[79] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg2_calendex.rdf\") + '\\n'\n",
    "    filelines[80] = os.path.join(outfall_dir, \"output_NPlesant_Custom_parent_esa.txt\") + '\\n'\n",
    "    filelines[81] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg1_esa.txt\") + '\\n'\n",
    "    filelines[82] = os.path.join(outfall_dir, \"output_NPlesant_Custom_deg2_esa.txt\") + '\\n'\n",
    "        \n",
    "    with open(outfall_file, \"w\") as write_file:\n",
    "        # write out file\n",
    "        write_file.writelines(filelines)\n",
    "    \n",
    "    # copy weather file into new file location\n",
    "    if mode == 'debug':\n",
    "        old_wet_path = os.path.join(main_path, \"master_debug\", \"vvwm_wet.dvf\")\n",
    "    elif mode == 'test':\n",
    "        old_wet_path = os.path.join(main_path, \"master_test\", \"vvwm_wet.dvf\")\n",
    "    elif mode =='run':\n",
    "        old_wet_path = os.path.join(weather_path, \"vvwm_wet.dvf\")\n",
    "    new_wet_path = os.path.join(outfall_dir, \"vvwm_wet.dvf\")\n",
    "    shutil.copyfile(old_wet_path, new_wet_path)\n",
    "\n",
    "    # copy exe into new file location\n",
    "    if sys.platform == \"linux\" or sys.platform == \"linux2\":\n",
    "        exe_bn = \"vvwm\"\n",
    "    elif sys.platform == \"win32\":\n",
    "        exe_bn = \"VVWM.exe\"\n",
    "    old_exe_path = os.path.join(exe_path, exe_bn)\n",
    "    new_exe_path = os.path.join(outfall_dir, \"VVWM.exe\")\n",
    "    shutil.copyfile(old_exe_path, new_exe_path)\n",
    "    \n",
    "    # run vvwm.exe (vvwm.exe [...]/outfall_31_xx/vvwmTransfer.txt)\n",
    "    command = new_exe_path + ' ' + outfall_file\n",
    "    subprocess.call(command)\n",
    "    \n",
    "    # read in produced data from the output of the vvwm run we just completed\n",
    "    output = pd.read_csv(filelines[68][:-1], \n",
    "                         usecols = [1], skiprows=5, names = [\"davg_bif_conc\"])*1000000\n",
    "    if mode == 'debug':\n",
    "        output['Sample_date'] = pd.date_range(start='1/1/2009', periods=103, freq='D')\n",
    "    elif mode == 'test':\n",
    "        output['Sample_date'] = pd.date_range(start='1/1/2009', periods=778, freq='D')\n",
    "    elif mode == 'run':\n",
    "        output['Sample_date'] = pd.date_range(start='1/1/2009', periods=3287, freq='D')\n",
    "    output['Site_code'] = o[-5:]\n",
    "    output = output.merge(obs_data, how = \"inner\", on = ['Sample_date','Site_code'])\n",
    "    output.set_index([np.datetime_as_string(output.Sample_date, unit = 'D'),'Site_code'], inplace = True)\n",
    "    output_df = output_df.append(output[['davg_bif_conc',]], ignore_index = False)\n",
    "\n",
    "# sort by date and site\n",
    "output_df = output_df.set_index([[\"_\".join([a,b[3:]]) for a,b in output_df.index]]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_df.to_dict()['davg_bif_conc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"rm -r \" + sdir_path + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2009-02-13_28': 113650000.0,\n",
       " '2009-04-07_28': 36769000000.0,\n",
       " '2009-04-13_28': 1238100000.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return(output_dict)\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We made it to the post-processing stage!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
