{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To activate debug mode, run 'inp_path = set_inp_path('debug')'.\n",
      "To activate test mode, run 'inp_path = set_inp_path('test')'.\n",
      "To activate run mode, run 'inp_path = set_inp_path('run')'.\n",
      "C:\\Users\\jstelman\\Git\\stelman_urban_pesticides\\master_debug\\NPlesantCreek.inp\n"
     ]
    }
   ],
   "source": [
    "import jn_setup\n",
    "from simulation_procedure import model, mode\n",
    "from tools.paths import *\n",
    "import pandas as pd, pyabc, hydroeval as he, numpy as np, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Priors. Get the values from that csv. Just for SWMM at first.\n",
    "\"\"\"\n",
    "swmm_ranges = pd.read_csv(os.path.join(master_path, \"lhs_param_ranges.csv\"), index_col=0,\n",
    "                           usecols = [\"Parameter\",\"Min\", \"Range\"])\n",
    "\n",
    "'''\n",
    "Link up with the vvwm priors and make one big list with 36 params\n",
    "'''\n",
    "vvwm_ranges = pd.read_csv(os.path.join(master_path, \"lhs_param_ranges_vvwm.csv\"), index_col=0,\n",
    "                           usecols = [\"Parameter\",\"Min\", \"Range\"])\n",
    "\n",
    "param_ranges = pd.concat([swmm_ranges, vvwm_ranges], axis = 0)\n",
    "\n",
    "if mode == \"debug\":\n",
    "    param_ranges = param_ranges.loc[['NImperv','kd']]\n",
    "\n",
    "priors = param_ranges.to_dict(\"index\")\n",
    "\n",
    "# borrowed from Jeff: <https://github.com/JeffreyMinucci/bee_neonic_abc/blob/master/pyabc_run.ipynb>\n",
    "prior = pyabc.Distribution(**{key: pyabc.RV(\"uniform\", loc = v['Min'], scale = v['Range'])\n",
    "                        for key, v in priors.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NImperv': {'Min': 0.01, 'Range': 0.015},\n",
       " 'kd': {'Min': 882.0, 'Range': 5028.0}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Distribution 'NImperv', 'kd'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the .new object\n",
    "### 1. Import observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2009-02-13_28': 0.0485, '2009-04-07_28': 0.0192, '2009-04-13_28': 0.00858}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import it again to make inspect it\n",
    "# specifically for TEST mode!\n",
    "if mode == 'debug':\n",
    "    with open(os.path.join(main_path, 'master_debug','debug_obs_data.txt'),'r') as read_file:\n",
    "        obs_dict = eval(read_file.read())\n",
    "elif mode == 'test':\n",
    "    with open(os.path.join(main_path, 'master_test','test_obs_data.txt'),'r') as read_file:\n",
    "        obs_dict = eval(read_file.read())\n",
    "elif mode == 'run':\n",
    "    with open(os.path.join(main_path, 'master','obs_data.txt'),'r') as read_file:\n",
    "        obs_dict = eval(read_file.read())\n",
    "obs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize dask client for dask distributed sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client#, LocalCluster\n",
    "# cluster = LocalCluster()#n_workers=(90/2), threads_per_worker = 2)  # Set for 96 vCPU compute instance\n",
    "# client = Client(cluster)#,timeout=400)\n",
    "\n",
    "# make it simpler\n",
    "# if __name__ == \"__main__\":\n",
    "client = Client()\n",
    "\n",
    "sampler = pyabc.sampler.DaskDistributedSampler(dask_client = client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set up a sqlite db directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79ef2cfc\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new ABC inference run\n",
    "dbid = uuid.uuid4().hex[0:8]\n",
    "print(dbid)\n",
    "database_dir = os.path.join(temp_path, 'results_db')  \n",
    "if not os.path.exists(database_dir):\n",
    "    os.mkdir(database_dir)\n",
    "db_path = (\"sqlite:///\" +\n",
    "           os.path.join(database_dir, \"test_pyabc_\" + dbid + \".db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining a Distance function\n",
    "\n",
    "We need to refactor the NSE distance function using the pyabc.Distance class.\n",
    "We will need the hydroeval library and the pyabc.SimpleFunctionDistance to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file to hold onto these NSEs for our own record\n",
    "with open(os.path.join(temp_path, \"NSEs_\" + dbid + \".txt\"), \"w\") as nse_file:\n",
    "    nse_file.write(\"NSEs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nse(x, x_0):\n",
    "    nse = he.evaluator(he.nse, \n",
    "                       simulation_s = np.array(list(x.values())), \n",
    "                       evaluation = np.array(list(x_0.values())))[0]\n",
    "    print(\"nse \", nse)\n",
    "    # make record\n",
    "    with open(os.path.join(temp_path, \"NSEs_\" + dbid + \".txt\"),\"a\") as nse_file:\n",
    "        nse_file.write(str(nse)+\"\\n\")\n",
    "    return nse\n",
    "    \n",
    "NSE = pyabc.SimpleFunctionDistance(fun=nse)\n",
    "\n",
    "# the best answer is 1\n",
    "# make one that measures distance from 1\n",
    "NSED = pyabc.SimpleFunctionDistance(fun = lambda x, x_0: 1 - nse(x, x_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define ABCSMC object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = pyabc.ABCSMC(model, prior, \n",
    "                   # might fix the dask problem too\n",
    "                   population_size = pyabc.ConstantPopulationSize(4), # just to shorten the run\n",
    "                   sampler = sampler,\n",
    "                   distance_function = NSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyabc.inference.smc.ABCSMC at 0x1fac4fbb430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Initialize a new abc run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyabc.storage.history.History at 0x1fac4fbb370>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.new(db_path, obs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nse  -8.184184856644206e+23\n",
      "nse  -1.9755207482243708e+23\n",
      "nse  -2.5016671401965104e+23\n",
      "nse  -2.169231926961757e+24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.core - ERROR - Exception while handling op heartbeat_worker\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jstelman\\Anaconda3\\envs\\swmm1\\lib\\site-packages\\distributed\\core.py\", line 493, in handle_comm\n",
      "    result = handler(comm, **msg)\n",
      "  File \"C:\\Users\\jstelman\\Anaconda3\\envs\\swmm1\\lib\\site-packages\\distributed\\scheduler.py\", line 2196, in heartbeat_worker\n",
      "    ws._executing = {\n",
      "  File \"C:\\Users\\jstelman\\Anaconda3\\envs\\swmm1\\lib\\site-packages\\distributed\\scheduler.py\", line 2197, in <dictcomp>\n",
      "    self.tasks[key]: duration for key, duration in executing.items()\n",
      "KeyError: 'full_submit_function-221a99befd31e26d3e2572cc3ad1dda8'\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n"
     ]
    }
   ],
   "source": [
    "# add 1 to generations\n",
    "history = abc.run(max_nr_populations=3, minimum_epsilon=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
